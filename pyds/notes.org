#+TITLE: Python Data Science Handbook Notes

:SETUP:
#+STARTUP: showall inlineimages
#+PROPERTY: header-args :session pyds :exports both :results raw drawer
#+INFOJS_OPT: view:t toc:t ltoc:0 mouse:underline buttons:0 path:http://thomasf.github.io/solarized-css/org-info.min.js
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="http://thomasf.github.io/solarized-css/solarized-dark.min.css" />
#+HTML_HEAD: <style>pre.example {background: #001e26;} table{margin: 0 auto;}</style>
#+BEGIN_SRC ipython :exports none :results silent
  from __future__ import print_function
  %matplotlib inline
  %config InlineBackend.rc={'figure.dpi': 120}
  import numpy as np
  import pandas as pd
  import matplotlib.pyplot as plt
  plt.style.use("ggplot")
#+END_SRC
:END:

* IPython
** Emacs
*** Completion on Windows
    To get Emacs Python shell completion on Windows, install pyreadline. Then it
    just works.

*** Disable pager in Emacs
   
    put this in ~${HOME}/.ipython/profile_default/startup/no-pager.py~

    #+BEGIN_SRC ipython :exports code :eval no
    from __future__ import print_function
    def page_printer(data, start=0, screen_lines=0, pager_cmd=None):
        if isinstance(data, dict):
            data = data['text/plain']
        print(data)
    import os
    TERM = os.environ.get('TERM', 'unknown')
    if TERM in ['emacs', 'dumb', 'xterm-color']:
        get_ipython().hooks.show_in_pager = page_printer
    #+END_SRC

*** Format DataFrame as org table
   
    put this in ~${HOME}/.ipython/profile_default/startup/org-formatter.py~
   
    #+BEGIN_SRC ipython :exports code :eval no
    import IPython, sys
    from tabulate import tabulate
    class OrgFormatter(IPython.core.formatters.BaseFormatter):
      def __call__(self, obj):
          try:
              if 'pandas' in sys.modules:
                  import pandas as pd
              else:
                  return None
              if (type(obj) == pd.core.frame.DataFrame):
                  return tabulate(obj, headers='keys', tablefmt='orgtbl')
          except:
              return None
    ip = get_ipython()
    ip.display_formatter.formatters['text/org'] = OrgFormatter()
    #+END_SRC

** Shell commands
   All shell commands can be used with ~!~ prefix.  Results can be assigned to
   python variables.  ~!~ functions run in temporary shell.  ~%~ *magic*
   functions has permanent effect. Many ~%~ magic functions can be used without
   ~%~, these are called *automagic* functions.

   #+BEGIN_SRC ipython
   files = !ls
   files
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[2]:
   : ['notes.html', 'notes.org', 'obipy']
   :END:

** Debugger
   ~%debug~ to enter debugger on last exception

** Timing
   + ~%timeit~ - one line, may run multiple times for short functions
   + ~%%timeit~ - works for multiple code lines, may run multple times
   + ~%time~ - only run one time
   + ~%%time~ - only run one time, multi line cell
   + ~%prun~ - profile function call

* NumPy
** Array creating functions
   - ~np.zeros(10, dtype=int)~
   - ~np.ones((3,5), dtype=float)~
   - ~np.full((3,5), 3.14)~
   - ~np.arange(0, 20, 2)~
   - ~np.linspace(0, 1, 5)~
   - ~np.random.random((3, 3))~
   - ~np.random.normal(0, 1, (3, 3))~ normally distributed random values
   - ~np.random.randint(0, 10, (3, 3))~
   - ~np.eye(3)~  3x3 identity matrix
   - ~np.empty(3)~ uninitialized array
** Array attributes
   
   #+BEGIN_SRC ipython :results output pp
   x3 = np.random.randint(10, size=(3, 4, 5))
   print("x3 ndim", x3.ndim)         # dimension
   print("x3 shape", x3.shape)       # shape
   print("x3 size", x3.size)         # total elements
   print("x3 dtype", x3.dtype)       # array type
   print("x3 itemsize", x3.itemsize) # bytes per item
   print("x3 nbytes", x3.nbytes)     # total bytes
   #+END_SRC

   #+RESULTS:
   : x3 ndim 3
   : x3 shape (3, 4, 5)
   : x3 size 60
   : x3 dtype int32
   : x3 itemsize 4
   : x3 nbytes 240

** Array slicing
   
   Slicing returns a *view* into the original. No copy is made.

   #+BEGIN_SRC ipython :results raw drawer
   x2 = np.random.randint(10, size=(3, 4))
   x2
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[4]:
   #+BEGIN_EXAMPLE
     array([[8, 1, 2, 5],
            [8, 1, 3, 8],
            [9, 3, 1, 7]])
   #+END_EXAMPLE
   :END:

   Extract 2x2

   #+BEGIN_SRC ipython
    x2[:2, :2]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[5]:
   #+BEGIN_EXAMPLE
     array([[8, 1],
            [8, 1]])
   #+END_EXAMPLE
   :END:

   Reverse
   #+BEGIN_SRC ipython
    x2[::-1, ::-1]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[6]:
   #+BEGIN_EXAMPLE
     array([[7, 1, 3, 9],
            [8, 3, 1, 8],
            [5, 2, 1, 8]])
   #+END_EXAMPLE
   :END:

   Get column
   #+BEGIN_SRC ipython
    x2[:, 0]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[7]:
   : array([8, 8, 9])
   :END:

   Get row
   #+BEGIN_SRC ipython
    x2[0, :]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[8]:
   : array([8, 1, 2, 5])
   :END:

   To make a copy,  use .copy()
   #+BEGIN_SRC ipython
   x2[:2, :2].copy()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   #+BEGIN_EXAMPLE
     array([[8, 1],
            [8, 1]])
   #+END_EXAMPLE
   :END:

** Change dimension
   
   With ~.reshape()~

   #+BEGIN_SRC ipython
   x = np.array([1,2,3])
   x.reshape((1,3))  # make row vector
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   : array([[1, 2, 3]])
   :END:

   #+BEGIN_SRC ipython
   x.reshape((3,1))  # make column vector
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   #+BEGIN_EXAMPLE
     array([[1],
            [2],
            [3]])
   #+END_EXAMPLE
   :END:

   Or with ~np.newaxis~

   #+BEGIN_SRC ipython
   x[np.newaxis, :]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[12]:
   : array([[1, 2, 3]])
   :END:

   #+BEGIN_SRC ipython
   x[:, np.newaxis]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[13]:
   #+BEGIN_EXAMPLE
     array([[1],
            [2],
            [3]])
   #+END_EXAMPLE
   :END:

** Merging and splitting

   Merging with ~np.concatenate()~, ~np.vstack()~, ~np.hstack()~

   #+BEGIN_SRC ipython
   np.concatenate([x2, x2]) # or np.vstack()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[14]:
   #+BEGIN_EXAMPLE
     array([[8, 1, 2, 5],
            [8, 1, 3, 8],
            [9, 3, 1, 7],
            [8, 1, 2, 5],
            [8, 1, 3, 8],
            [9, 3, 1, 7]])
   #+END_EXAMPLE
   :END:

   #+BEGIN_SRC ipython
   np.concatenate([x2, x2], axis=1) # or np.hstack()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[15]:
   #+BEGIN_EXAMPLE
     array([[8, 1, 2, 5, 8, 1, 2, 5],
            [8, 1, 3, 8, 8, 1, 3, 8],
            [9, 3, 1, 7, 9, 3, 1, 7]])
   #+END_EXAMPLE
   :END:

   Split with ~np.split()~ , ~np.hsplit()~ , ~np.vsplit()~

   #+BEGIN_SRC ipython
   x = [1, 2, 3, 99, 99, 3, 2, 1]
   np.split(x, [3, 5]) # pass a list of split points
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[16]:
   : [array([1, 2, 3]), array([99, 99]), array([3, 2, 1])]
   :END:

** Specify output container

   To avoid creating temporaries.
   
   #+BEGIN_SRC ipython
   x = np.arange(5)
   y = np.empty(5)
   np.multiply(x, 10, out=y)
   y
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[17]:
   : array([  0.,  10.,  20.,  30.,  40.])
   :END:

   This can even be used with array views. For example, we can write the results
   of a computation to every other element of a specified array:

   #+BEGIN_SRC ipython
   y = np.zeros(10)
   np.power(2, x, out=y[::2])
   y
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[18]:
   : array([  1.,   0.,   2.,   0.,   4.,   0.,   8.,   0.,  16.,   0.])
   :END:

** reduce() and accumulate()
   
   ufuncs supports ~reduce()~ and ~accumulate()~

   ~reduce()~ computes a final result.
   
   #+BEGIN_SRC ipython
   x = np.arange(1, 6)
   np.add.reduce(x)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[19]:
   : 15
   :END:

   ~accumulate()~ saves all intermediate results.

   #+BEGIN_SRC ipython
   np.add.accumulate(x)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[20]:
   : array([ 1,  3,  6, 10, 15], dtype=int32)
   :END:

** Sort and index sort

   ~np.sort()~ returns new copy of sorted array.

   ~x.sort()~ sorts ~x~ in place.

   ~np.argsort()~ returns sorted index array.

   #+BEGIN_SRC ipython
   x = np.array([2,1,4,3,5])
   np.sort(x)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[21]:
   : array([1, 2, 3, 4, 5])
   :END:

   #+BEGIN_SRC ipython
   np.argsort(x)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[22]:
   : array([1, 0, 3, 2, 4], dtype=int64)
   :END:

** Example: k-Nearest Neighbors

   https://jakevdp.github.io/PythonDataScienceHandbook/02.08-sorting.html

   - Create 10 random points.
   - Compute the distance between each pair of points.
   - Take the 2 left most columns.
   
   #+BEGIN_SRC ipython :ipyfile ./obipy/dmv85B.png
   np.random.seed(42)
   X = np.random.rand(10, 2)
   dist_sq = np.sum((X[:, np.newaxis, :] - X[np.newaxis, :, :]) ** 2, axis=-1)
   K = 2
   nearest_partition = np.argpartition(dist_sq, K + 1, axis=1)
   plt.scatter(X[:, 0], X[:, 1], s=100)
   for i in range(X.shape[0]):
       for j in nearest_partition[i, :K+1]:
           # plot a line from X[i] to X[j]
           # use some zip magic to make it happen:
           plt.plot(*zip(X[j], X[i]), color='black')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[38]:
   [[file:./obipy/dmv85B.png]]
   :END:

* Pandas
** Series
   
   Series is like strong typed dictionary.

   Series supports indexing with keys: ~data['b']~

   And checking presence with operator ~in~: ~'a' in data~

*** Constructing
    
    data can be a scalar, which is repeated to fill the specified index:
    
    #+BEGIN_SRC ipython
    pd.Series(5, index=[100, 200, 300])
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[24]:
    #+BEGIN_EXAMPLE
      100    5
      200    5
      300    5
      dtype: int64
    #+END_EXAMPLE
    :END:

    data can be a dictionary:

    #+BEGIN_SRC ipython
    pd.Series({2:'a', 1:'b', 3:'c'})
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[25]:
    #+BEGIN_EXAMPLE
      1    b
      2    a
      3    c
      dtype: object
    #+END_EXAMPLE
    :END:

    Explicitly specify index:

    #+BEGIN_SRC ipython
    pd.Series({2:'a', 1:'b', 3:'c'}, index=[3, 2])
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[26]:
    #+BEGIN_EXAMPLE
      3    c
      2    a
      dtype: object
    #+END_EXAMPLE
    :END:

    In above example, 'b' is dropped, as 1 is not in the index.

** DataFrame

   Similar to Series, but 2D, where both rows and columns have generalized
   index.

   It can be seen as a dictionary of column names to series.

   Assume we have this DataFrame:

   #+BEGIN_SRC ipython
     area = pd.Series({'California': 423967, 'Texas': 695662,
                       'New York': 141297, 'Florida': 170312,
                       'Illinois': 149995})
     pop = pd.Series({'California': 38332521, 'Texas': 26448193,
                      'New York': 19651127, 'Florida': 19552860,
                      'Illinois': 12882135})
     data = pd.DataFrame({'area':area, 'pop':pop})
     data
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[89]:
   #+BEGIN_EXAMPLE
                   area       pop
     California  423967  38332521
     Florida     170312  19552860
     Illinois    149995  12882135
     New York    141297  19651127
     Texas       695662  26448193
   #+END_EXAMPLE
   :END:

   Access columns like dictionary:
   
   #+BEGIN_SRC ipython
     data['area'] # or just data.area
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[28]:
   #+BEGIN_EXAMPLE
     California    423967
     Florida       170312
     Illinois      149995
     New York      141297
     Texas         695662
     Name: area, dtype: int64
   #+END_EXAMPLE
   :END:

   Never assign columns via attribute syntax. For example, use ~data['pop'] = z~
   rather than ~data.pop = z~. Otherwise it can overwrite method names.

   Adding new column:
   
   #+BEGIN_SRC ipython
   data['density'] = data['pop'] / data['area']
   data
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[29]:
   #+BEGIN_EXAMPLE
                   area       pop     density
     California  423967  38332521   90.413926
     Florida     170312  19552860  114.806121
     Illinois    149995  12882135   85.883763
     New York    141297  19651127  139.076746
     Texas       695662  26448193   38.018740
   #+END_EXAMPLE
   :END:

*** Indexing DataFrames
    
    Indexing as NumPy array:

    #+BEGIN_SRC ipython
    data.iloc[:3, :2]
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[30]:
    #+BEGIN_EXAMPLE
                    area       pop
      California  423967  38332521
      Florida     170312  19552860
      Illinois    149995  12882135
    #+END_EXAMPLE
    :END:

    Indexing with column and row names:

    #+BEGIN_SRC ipython
    data.loc[:'Illinois', :'pop']
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[31]:
    #+BEGIN_EXAMPLE
                    area       pop
      California  423967  38332521
      Florida     170312  19552860
      Illinois    149995  12882135
    #+END_EXAMPLE
    :END:

    *While indexing refers to columns, slicing refers to rows:*

    #+BEGIN_SRC ipython
    data['Florida':'Illinois']
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[32]:
    #+BEGIN_EXAMPLE
                  area       pop     density
      Florida   170312  19552860  114.806121
      Illinois  149995  12882135   85.883763
    #+END_EXAMPLE
    :END:

    *Such slices can also refer to rows by number rather than by index::*

    #+BEGIN_SRC ipython
    data[1:3]
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[33]:
    #+BEGIN_EXAMPLE
                  area       pop     density
      Florida   170312  19552860  114.806121
      Illinois  149995  12882135   85.883763
    #+END_EXAMPLE
    :END:

*** Operations

    All NumPy ufuncs work on Series and DataFrames, and indexes are preserved.

    #+BEGIN_SRC ipython
      df = pd.DataFrame(np.random.randint(0, 10, (3, 4)),
                        columns=['A', 'B', 'C', 'D'])
      np.sin(df * np.pi / 4)
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[34]:
    #+BEGIN_EXAMPLE
                    A             B             C         D
      0  7.071068e-01  1.000000e+00 -1.000000e+00  0.707107
      1 -2.449294e-16  1.000000e+00  1.224647e-16  1.000000
      2 -1.000000e+00  1.224647e-16 -2.449294e-16 -1.000000
    #+END_EXAMPLE
    :END:

    *Pandas automatically aligns indexes, and fills missing data with NaN*

    #+BEGIN_SRC ipython
      area = pd.Series({'Alaska': 1723337, 'Texas': 695662,
                        'California': 423967}, name='area')
      population = pd.Series({'California': 38332521, 'Texas': 26448193,
                              'New York': 19651127}, name='population')
      population / area
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[35]:
    #+BEGIN_EXAMPLE
      Alaska              NaN
      California    90.413926
      New York            NaN
      Texas         38.018740
      dtype: float64
    #+END_EXAMPLE
    :END:

    This works because the resulting array contains the union of the indices of
    the inputs:

    #+BEGIN_SRC ipython
      area.index | population.index
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[36]:
    : Index(['Alaska', 'California', 'New York', 'Texas'], dtype='object')
    :END:

    We can change the fill value: ~A.add(B, fill_value=0)~
  
    | Python Operator | Pandas Method(s)           |
    |-----------------+----------------------------|
    | +               | add()                      |
    | -               | sub(), subtract()          |
    | *               | mul(), multiply()          |
    | /               | truediv(), div(), divide() |
    | //              | floordiv()                 |
    | %               | mod()                      |
    | **              | pow()                      |

    Operations between DataFrame and Series are by default by rows. To make it
    work by columns, use the above functions and specify axis (0=column, 1= row)

    #+BEGIN_SRC ipython
    df = pd.DataFrame(np.random.randint(10, size=(3, 4)), columns=list('QRST'))
    #df - df.iloc[0] # first row becomes 0, other rows minus row0
    #df - df.Q       # this is not what you think
    df.subtract(df['Q'], axis=0)
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[37]:
    #+BEGIN_EXAMPLE
         Q  R  S  T
      0  0  2  7  0
      1  0 -1  0 -5
      2  0  2  5  6
    #+END_EXAMPLE
    :END:
*** Missing data
    NaN is often used. NumPy has functions to work on them.
    #+BEGIN_SRC ipython
    vals2 = np.array([1, np.nan, 3, 4])
    np.nansum(vals2), np.nanmin(vals2), np.nanmax(vals2)
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[2]:
    : (8.0, 1.0, 4.0)
    :END:

    Pandas auto cast data to float when it needs to use NaN to represent missing
    data.

    #+BEGIN_SRC ipython
    x = pd.Series(range(2), dtype=int)
    x[0] = None
    x
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[5]:
    #+BEGIN_EXAMPLE
      0    NaN
      1    1.0
      dtype: float64
    #+END_EXAMPLE
    :END:

    | Typeclass | Conversion When Storing NAs | NA Sentinel Value |
    |-----------+-----------------------------+-------------------|
    | floating  | No change                   | np.nan            |
    | object    | No change                   | None or np.nan    |
    | integer   | Cast to float64             | np.nan            |
    | boolean   | Cast to object              | None or np.nan    |

    Pandas functions for NaN (or None, they are interchangeable in Pandas)

    * ~isnull()~: Generate a boolean mask indicating missing values
    * ~notnull()~: Opposite of isnull()
    * ~dropna()~: Return a filtered version of the data
      - Can drop entire row or column with 'axis'
      - Can set threshold of dropping row or column with 'thresh'
    * ~fillna()~: Return a copy of the data with missing values filled or imputed
      - Can forward fill with ~method='ffill'~ and back fill with ~method='bfill'~
*** Hierarchical Indexing

